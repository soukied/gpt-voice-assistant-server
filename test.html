<!DOCTYPE html>
<html>
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width,initial-scale=1.0">
	<title> GPT Voice Assistant  </title>
	<script src='https://cdnjs.cloudflare.com/ajax/libs/showdown/2.1.0/showdown.min.js'></script>
</head>
<body>
	<h1> GPT 3.5 dengan suara </h1>
	<button id="start-record" onclick="AudioRecorder.start()"> Start Record </button>
	<button id="stop-record" onclick="AudioRecorder.stop()"> Stop Record </button>
	<p id="output">
	</p>
	<script>
		let fetching_data = false;

		const [writeOutput, clearOutput]  = (()=>{
			let output = "";
			let converter = new showdown.Converter();
			let element = document.querySelector("#output");
			return [
				(newOutput) =>{
					output += newOutput;
					element.innerHTML = converter.makeHtml(output);
				},
				() => {
					element.innerHTML = "";
					output = "";
				}
			]
		})();

		async function ChatGPT_request(audio_blob) {
			clearOutput();
			const form = new FormData();
			form.append('audio', audio_blob, "audio.wav");
			const response = await fetch('http://localhost:3000/audiorequest', {
				method: "POST",
				body: form,
			});
			const reader = response.body.getReader();
			let unfinished_chunk = null;
			while (true) {
				const {done, value} = await reader.read();
				let data = new TextDecoder().decode(value).replaceAll("data:","").split("\n\n");
				for (let content of data) {
					if (unfinished_chunk) {
						const sliced_content = unfinished_chunk + content;
						unfinished_chunk = null;
						const parsed_data = JSON.parse(sliced_content.replaceAll('data:',''))
						const output = parsed_data.choices[0].delta.content;
						writeOutput(output ? output : "");
						continue;
				}
					if (content == "" || content == " [DONE]") break;
					let sliced_content = content
					try {
						const parsed_data = JSON.parse(sliced_content)
						const output = parsed_data.choices[0].delta.content;
						writeOutput(output ? output : "");
					} catch(e) {
						unfinished_chunk = sliced_content;
						console.error("Data parsing yang salah: " + content);
					}
				}
				if (done) {
					console.log("Selesai fetching");
					break;
				}
			}
		}

		let AudioRecorder = {
			mediaStream : null,
			audioChunks: null ,
			recording: false,
			_start(stream) {
				this.recording = true;
				this.mediaStream = new MediaRecorder(stream);
				this.mediaStream.ondataavailable = (e) => {
					this.audioChunks.push(e.data);
					console.log(this.audioChunks);
					console.log(this.mediaStream.state);
					const blob = new Blob(this.audioChunks, { type: "audio/ogg; codecs=opus" });
					ChatGPT_request(blob);
				}
				this.mediaStream.start();
				console.log(this.mediaStream.state);
			},

			start() {
				if (this.recording) return;
				if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
				  console.log("getUserMedia supported.");
				  navigator.mediaDevices
					.getUserMedia( { audio: true })
						.then((stream) => this._start(stream))
					// Error callback
					.catch((err) =>
						console.error(`The following getUserMedia error occurred: ${err}`)
					);
				} else {
				  console.log("getUserMedia not supported on your browser!");
					return;
				}
			},

			stop() {
				if (this.recording && this.mediaStream)  {
					this.mediaStream.stop();
					this.audioChunks = [];
					this.recording = false;
				}
			}
		}
	</script>
</body>
</html>
